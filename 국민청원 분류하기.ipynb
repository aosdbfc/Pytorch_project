{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2fe74902",
   "metadata": {},
   "source": [
    "## 크롤링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7af8ba67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('crawling.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc52bddf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>content</th>\n",
       "      <th>count</th>\n",
       "      <th>end</th>\n",
       "      <th>start</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>인권/성평등</td>\n",
       "      <td>본인은 2019년 8월 경 서울지방병무청 제1검사장 탈의실에서 믿을 수 없는 것을 ...</td>\n",
       "      <td>267</td>\n",
       "      <td>2020-02-01</td>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>서울지방병무청 탈의실에 설치된 CCTV에 대한 진상규명을 요구한다. 또한 인권위의 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>경제민주화</td>\n",
       "      <td>우리 나라 코스피 시총이 미국 애플보다 작다는 설이 돌 정도로 한국의 주식시장은 저...</td>\n",
       "      <td>271</td>\n",
       "      <td>2020-02-01</td>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>주식시장 활성화 및 소액(개미)투자자 보호</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>행정</td>\n",
       "      <td>억울한 일로 국민청원을 신청합니다.\\r\\n\\r\\r\\n 저는 **구치소 **교도관입니...</td>\n",
       "      <td>198</td>\n",
       "      <td>2020-02-01</td>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>교정기관의 민낮</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>안전/환경</td>\n",
       "      <td>미세먼지의 심각성은 이제 적극적인 대안을 요구 하고 있습니다.\\r\\r\\n우리 일상에...</td>\n",
       "      <td>170</td>\n",
       "      <td>2020-02-01</td>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>미세먼지 저감 대책</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>교통/건축/국토</td>\n",
       "      <td>저는 우선 아이셋의 부모입니다.\\r\\r\\n식구가 많은편이고 아이들이 성장함에 따라 ...</td>\n",
       "      <td>2,127</td>\n",
       "      <td>2020-02-01</td>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>악질세입자 방지를 위한 세입자보호법을 재정해주세요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10876</th>\n",
       "      <td>기타</td>\n",
       "      <td>**** 신용점수제는 전면 재검토해야 합니다\\r\\n\\r\\r\\n신용점수제의 도입취지는...</td>\n",
       "      <td>521</td>\n",
       "      <td>2021-01-30</td>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>****의 신용점수제는 대국민 사기극!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10877</th>\n",
       "      <td>교통/건축/국토</td>\n",
       "      <td>저는 서울 시민입니다 당연히 마을버스도 이용하고 있습니다 마을버스 승객은 40%가 ...</td>\n",
       "      <td>333</td>\n",
       "      <td>2021-01-30</td>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>서울 마을버스 업체 지원 정부에서 해결해주세요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10878</th>\n",
       "      <td>정치개혁</td>\n",
       "      <td>광복 이래 역사를 말할 것도 없고, 근래에 들어서도 수많은 사건들이 공직자들에 의해...</td>\n",
       "      <td>1,557</td>\n",
       "      <td>2021-01-30</td>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>과거사위원회를 상설기구로 설치하여 주십시오.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10879</th>\n",
       "      <td>보건복지</td>\n",
       "      <td>의사들은 코로나로 가장 위급한 시기에 국민에 생명을 잡고 파업을 하였습니다     ...</td>\n",
       "      <td>18,205</td>\n",
       "      <td>2021-01-30</td>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>정부와 보건복지부에 요청 합니다 의대생 국시 절대 반대 합니다</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10880</th>\n",
       "      <td>보건복지</td>\n",
       "      <td>안녕하세요.\\r\\n\\r\\r\\n오늘 정부가 내년 의사 국가고시를 1월에 실시하는 발표...</td>\n",
       "      <td>6,299</td>\n",
       "      <td>2021-01-30</td>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>내년 의사 국가고시를 1월에 추가로 실시하면서 정부를 믿고 올해 응시한 423명을 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10881 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       category                                            content   count  \\\n",
       "0        인권/성평등  본인은 2019년 8월 경 서울지방병무청 제1검사장 탈의실에서 믿을 수 없는 것을 ...     267   \n",
       "1         경제민주화  우리 나라 코스피 시총이 미국 애플보다 작다는 설이 돌 정도로 한국의 주식시장은 저...     271   \n",
       "2            행정  억울한 일로 국민청원을 신청합니다.\\r\\n\\r\\r\\n 저는 **구치소 **교도관입니...     198   \n",
       "3         안전/환경  미세먼지의 심각성은 이제 적극적인 대안을 요구 하고 있습니다.\\r\\r\\n우리 일상에...     170   \n",
       "4      교통/건축/국토  저는 우선 아이셋의 부모입니다.\\r\\r\\n식구가 많은편이고 아이들이 성장함에 따라 ...   2,127   \n",
       "...         ...                                                ...     ...   \n",
       "10876        기타  **** 신용점수제는 전면 재검토해야 합니다\\r\\n\\r\\r\\n신용점수제의 도입취지는...     521   \n",
       "10877  교통/건축/국토  저는 서울 시민입니다 당연히 마을버스도 이용하고 있습니다 마을버스 승객은 40%가 ...     333   \n",
       "10878      정치개혁  광복 이래 역사를 말할 것도 없고, 근래에 들어서도 수많은 사건들이 공직자들에 의해...   1,557   \n",
       "10879      보건복지  의사들은 코로나로 가장 위급한 시기에 국민에 생명을 잡고 파업을 하였습니다     ...  18,205   \n",
       "10880      보건복지  안녕하세요.\\r\\n\\r\\r\\n오늘 정부가 내년 의사 국가고시를 1월에 실시하는 발표...   6,299   \n",
       "\n",
       "              end       start  \\\n",
       "0      2020-02-01  2020-01-02   \n",
       "1      2020-02-01  2020-01-02   \n",
       "2      2020-02-01  2020-01-02   \n",
       "3      2020-02-01  2020-01-02   \n",
       "4      2020-02-01  2020-01-02   \n",
       "...           ...         ...   \n",
       "10876  2021-01-30  2020-12-31   \n",
       "10877  2021-01-30  2020-12-31   \n",
       "10878  2021-01-30  2020-12-31   \n",
       "10879  2021-01-30  2020-12-31   \n",
       "10880  2021-01-30  2020-12-31   \n",
       "\n",
       "                                                   title  \n",
       "0      서울지방병무청 탈의실에 설치된 CCTV에 대한 진상규명을 요구한다. 또한 인권위의 ...  \n",
       "1                                주식시장 활성화 및 소액(개미)투자자 보호  \n",
       "2                                               교정기관의 민낮  \n",
       "3                                             미세먼지 저감 대책  \n",
       "4                           악질세입자 방지를 위한 세입자보호법을 재정해주세요.  \n",
       "...                                                  ...  \n",
       "10876                              ****의 신용점수제는 대국민 사기극!  \n",
       "10877                          서울 마을버스 업체 지원 정부에서 해결해주세요  \n",
       "10878                           과거사위원회를 상설기구로 설치하여 주십시오.  \n",
       "10879                 정부와 보건복지부에 요청 합니다 의대생 국시 절대 반대 합니다  \n",
       "10880  내년 의사 국가고시를 1월에 추가로 실시하면서 정부를 믿고 올해 응시한 423명을 ...  \n",
       "\n",
       "[10881 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c366a82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'우리 나라 코스피 시총이 미국 애플보다 작다는 설이 돌 정도로 한국의 주식시장은 저평가된 시장이라고 합니다. 하지만 투자매력이 없다고도 합니다.이렇게 말하는 이유가 어디 있습니까? 바로 투자를 해도 수익을 기대하기 어렵다는 인식이 이미 널리 퍼져 있다는 것입니다.\\r\\n\\r\\r\\n지금은 투자매력이 없어서 그렇지,..우리 나라 시중 부동 자금이 어마어마 한 것으로 알려진 것과, 외국 투자 자본 또한 실로 어마무지하게 많다는 것도 알고있습니다. 그러나 이 투자금이 주식시장으로 원활하게 순환이 안되고 있다는데 있습니다.\\r\\n\\r\\r\\n정부는 유휴자금이 주식 시장으로 들어오게 분위기를 띄어줘야 하는데,... 그렇지 못한 현실이 안타깝다고 생각합니다.\\r\\r\\n국가가 지원해 돈 들이기가 어려우면,정부에서 정서적인 말이라도 활성화를 위한 관심표명과 정책적으로 지원만 해도 시장분위기는 많이 좋아질 것이라 확신합니다. \\r\\n\\r\\r\\n그래서 저는 정부에 다음과 같이 청원합니다.\\r\\r\\n주식시장에 더 큰 충격 오기 전에 정부가 예방 조치를 할 수 있는데까지 노력해 주시기를 당부 드리면서,...\\r\\n\\r\\r\\n첫째,주식시장 활성화와 부양에 대한 정부의 의지를 표명해 주십시오 \\r\\n\\r\\r\\n둘째,  코스닥 종목은 공매도 제외시켜 주세요.\\r\\n\\r\\r\\n공매도 제도를 아예 없애버리면 좋겠지만 제도를 살린다면 적용 시장에서 코스닥 종목은 제외 해 주어야 체력이 약한 코스닥 시장을 안정시킬 수 있다고 봅니다 \\r\\n\\r\\r\\n셋째, 거래시장의 주식거래세를 더 낮춰 주세요 \\r\\n\\r\\r\\n특히 개미(소액)투자에 동일한 요율로 부과하는 것은 너무나 불공정 하다고 봅니다.\\r\\n\\r\\r\\n넷째, 중,장기 보유자에 대한 우대 차원에서 보유기간을 설정하여 주세요.\\r\\n\\r\\r\\n이는 장기 보유자에 대한 혜택을 주어 초단타매매 등 시장 질서를 교란하는 투자자와 분리하는 제도를 도입해 시장 안정화에 기여해 주시길 간곡히 부탁드리면서 청원합니다.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[1]['content']  # 전처리 전"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9784c055",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def remove_white_space(text):\n",
    "    text = re.sub(r'[\\t\\r\\n\\f\\v]', ' ', str(text))\n",
    "    return text\n",
    "\n",
    "def remove_special_char(text):\n",
    "    text = re.sub('[^ ㄱ-ㅣ가-힣 0-9]+', ' ', str(text))\n",
    "    return text\n",
    "\n",
    "df.title = df.title.apply(remove_white_space)\n",
    "df.title = df.title.apply(remove_special_char)\n",
    "\n",
    "df.content = df.content.apply(remove_white_space)\n",
    "df.content = df.content.apply(remove_special_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8af70b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'우리 나라 코스피 시총이 미국 애플보다 작다는 설이 돌 정도로 한국의 주식시장은 저평가된 시장이라고 합니다  하지만 투자매력이 없다고도 합니다 이렇게 말하는 이유가 어디 있습니까  바로 투자를 해도 수익을 기대하기 어렵다는 인식이 이미 널리 퍼져 있다는 것입니다      지금은 투자매력이 없어서 그렇지 우리 나라 시중 부동 자금이 어마어마 한 것으로 알려진 것과  외국 투자 자본 또한 실로 어마무지하게 많다는 것도 알고있습니다  그러나 이 투자금이 주식시장으로 원활하게 순환이 안되고 있다는데 있습니다      정부는 유휴자금이 주식 시장으로 들어오게 분위기를 띄어줘야 하는데  그렇지 못한 현실이 안타깝다고 생각합니다    국가가 지원해 돈 들이기가 어려우면 정부에서 정서적인 말이라도 활성화를 위한 관심표명과 정책적으로 지원만 해도 시장분위기는 많이 좋아질 것이라 확신합니다       그래서 저는 정부에 다음과 같이 청원합니다    주식시장에 더 큰 충격 오기 전에 정부가 예방 조치를 할 수 있는데까지 노력해 주시기를 당부 드리면서      첫째 주식시장 활성화와 부양에 대한 정부의 의지를 표명해 주십시오      둘째   코스닥 종목은 공매도 제외시켜 주세요      공매도 제도를 아예 없애버리면 좋겠지만 제도를 살린다면 적용 시장에서 코스닥 종목은 제외 해 주어야 체력이 약한 코스닥 시장을 안정시킬 수 있다고 봅니다      셋째  거래시장의 주식거래세를 더 낮춰 주세요      특히 개미 소액 투자에 동일한 요율로 부과하는 것은 너무나 불공정 하다고 봅니다      넷째  중 장기 보유자에 대한 우대 차원에서 보유기간을 설정하여 주세요      이는 장기 보유자에 대한 혜택을 주어 초단타매매 등 시장 질서를 교란하는 투자자와 분리하는 제도를 도입해 시장 안정화에 기여해 주시길 간곡히 부탁드리면서 청원합니다 '"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[1]['content']  # 전처리 후"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27b4cec",
   "metadata": {},
   "source": [
    "## 토크나이징 및 변수 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ec5d145",
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "\n",
    "okt = Okt()\n",
    "\n",
    "df['title_token'] = df.title.apply(okt.morphs)\n",
    "df['content_token'] = df.content.apply(okt.nouns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55dd6a2b",
   "metadata": {},
   "source": [
    "### 파생변수 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13aa5a74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category         object\n",
      "content          object\n",
      "count             int64\n",
      "end              object\n",
      "start            object\n",
      "title            object\n",
      "title_token      object\n",
      "content_token    object\n",
      "token_final      object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "df['token_final'] = df.title_token + df.content_token\n",
    "\n",
    "df['count'] = df['count'].replace({',' : ''}, regex = True).apply(lambda x : int(x))\n",
    "\n",
    "print(df.dtypes)\n",
    "\n",
    "df['label'] = df['count'].apply(lambda x: 'Yes' if x>=1000 else 'No')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fbd1de64",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_drop = df[['token_final', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10af18a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token_final</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[서울, 지방, 병무청, 탈의실, 에, 설치, 된, 에, 대한, 진상, 규명, 을,...</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[주식시장, 활성화, 및, 소액, 개미, 투자자, 보호, 우리, 나라, 코스피, 총...</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[교정, 기관, 의, 민낮, 일로, 국민, 청원, 신청, 저, 구치소, 교도관, 이...</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[미세먼지, 저, 감, 대책, 미세먼지, 심각, 성은, 이제, 적극, 대안, 요구,...</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[악질, 세, 입자, 방지, 를, 위, 한, 세, 입자, 보호, 법, 을, 재정, ...</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         token_final label\n",
       "0  [서울, 지방, 병무청, 탈의실, 에, 설치, 된, 에, 대한, 진상, 규명, 을,...    No\n",
       "1  [주식시장, 활성화, 및, 소액, 개미, 투자자, 보호, 우리, 나라, 코스피, 총...    No\n",
       "2  [교정, 기관, 의, 민낮, 일로, 국민, 청원, 신청, 저, 구치소, 교도관, 이...    No\n",
       "3  [미세먼지, 저, 감, 대책, 미세먼지, 심각, 성은, 이제, 적극, 대안, 요구,...    No\n",
       "4  [악질, 세, 입자, 방지, 를, 위, 한, 세, 입자, 보호, 법, 을, 재정, ...   Yes"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_drop.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec67e457",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_drop.to_csv('df_drop.csv', index = False, encoding = 'utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45149ef8",
   "metadata": {},
   "source": [
    "## 단어임베딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "99944372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec<vocab=42642, vector_size=100, alpha=0.025>\n",
      "[('음주', 0.8821665048599243), ('무면허', 0.8211634755134583), ('뺑소니', 0.8074896335601807), ('살인자', 0.7676025629043579), ('경범죄', 0.754641592502594), ('강력범죄', 0.7517711520195007), ('살인죄', 0.7454974055290222), ('전과자', 0.7365532517433167), ('형량', 0.7302147150039673), ('승자', 0.7286303639411926)]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "embedding_model = Word2Vec(df_drop['token_final'], \n",
    "                           sg = 1, # skip-gram\n",
    "                           #size = 100, \n",
    "                           window = 2, \n",
    "                           min_count = 1, \n",
    "                           workers = 4\n",
    "                           )\n",
    "\n",
    "print(embedding_model)\n",
    "\n",
    "model_result = embedding_model.wv.most_similar(\"음주운전\")\n",
    "print(model_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bb269215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('음주', 0.8821665048599243), ('무면허', 0.8211634755134583), ('뺑소니', 0.8074896335601807), ('살인자', 0.7676025629043579), ('경범죄', 0.754641592502594), ('강력범죄', 0.7517711520195007), ('살인죄', 0.7454974055290222), ('전과자', 0.7365532517433167), ('형량', 0.7302147150039673), ('승자', 0.7286303639411926)]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "embedding_model.wv.save_word2vec_format('petitions_tokens_w2v') # 모델 저장\n",
    "loaded_model = KeyedVectors.load_word2vec_format('petitions_tokens_w2v') # 모델 로드\n",
    "\n",
    "model_result = loaded_model.most_similar(\"음주운전\")\n",
    "print(model_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "af32c1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import RandomState\n",
    "\n",
    "rng = RandomState()\n",
    "\n",
    "tr = df_drop.sample(frac=0.8, random_state=rng)\n",
    "val = df_drop.loc[~df_drop.index.isin(tr.index)]\n",
    "\n",
    "tr.to_csv('train.csv', index=False, encoding='utf-8-sig')\n",
    "val.to_csv('validation.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1e89a125",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Field' from 'torchtext.data' (C:\\Users\\aosdb\\anaconda3\\lib\\site-packages\\torchtext\\data\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchtext\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchtext\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Field\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtokenizer\u001b[39m(text):\n\u001b[0;32m      5\u001b[0m     text \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mstr\u001b[39m(text))\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'Field' from 'torchtext.data' (C:\\Users\\aosdb\\anaconda3\\lib\\site-packages\\torchtext\\data\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import torchtext\n",
    "from torchtext.data import Field\n",
    "\n",
    "def tokenizer(text):\n",
    "    text = re.sub('[\\[\\]\\']', '', str(text))\n",
    "    text = text.split(', ')\n",
    "    return text\n",
    "\n",
    "#TEXT = Field(tokenize=tokenizer)\n",
    "#LABEL = Field(sequential = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "56add8b2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TabularDataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#from torchtext.data import TabularDataset\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m train, validation \u001b[38;5;241m=\u001b[39m \u001b[43mTabularDataset\u001b[49m\u001b[38;5;241m.\u001b[39msplits(\n\u001b[0;32m      4\u001b[0m     path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      5\u001b[0m     train \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain.csv\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      6\u001b[0m     validation \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalidation.csv\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcsv\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      8\u001b[0m     fields \u001b[38;5;241m=\u001b[39m [(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m, TEXT), (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m, LABEL)],\n\u001b[0;32m      9\u001b[0m     skip_header \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     10\u001b[0m )\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain:\u001b[39m\u001b[38;5;124m\"\u001b[39m, train[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtext,  train[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mlabel)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation:\u001b[39m\u001b[38;5;124m\"\u001b[39m, validation[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtext, validation[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mlabel)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'TabularDataset' is not defined"
     ]
    }
   ],
   "source": [
    "from torchtext.data import TabularDataset\n",
    "\n",
    "train, validation = TabularDataset.splits(\n",
    "    path = '',\n",
    "    train = 'train.csv',\n",
    "    validation = 'validation.csv',\n",
    "    format = 'csv',\n",
    "    fields = [('text', TEXT), ('label', LABEL)],\n",
    "    skip_header = True\n",
    ")\n",
    "\n",
    "print(\"Train:\", train[0].text,  train[0].label)\n",
    "print(\"Validation:\", validation[0].text, validation[0].label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ab657f7d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'BucketIterator' from 'torchtext.data' (C:\\Users\\aosdb\\anaconda3\\lib\\site-packages\\torchtext\\data\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchtext\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvocab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Vectors\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchtext\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BucketIterator\n\u001b[0;32m      5\u001b[0m vectors \u001b[38;5;241m=\u001b[39m Vectors(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/petitions_tokens_w2v\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      7\u001b[0m TEXT\u001b[38;5;241m.\u001b[39mbuild_vocab(train, vectors \u001b[38;5;241m=\u001b[39m vectors, min_freq \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m, max_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'BucketIterator' from 'torchtext.data' (C:\\Users\\aosdb\\anaconda3\\lib\\site-packages\\torchtext\\data\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchtext.vocab import Vectors\n",
    "from torchtext.data import BucketIterator\n",
    "\n",
    "vectors = Vectors(name=\"data/petitions_tokens_w2v\")\n",
    "\n",
    "TEXT.build_vocab(train, vectors = vectors, min_freq = 1, max_size = None)\n",
    "LABEL.build_vocab(train)\n",
    "\n",
    "vocab = TEXT.vocab\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "train_iter, validation_iter = BucketIterator.splits(\n",
    "    datasets = (train, validation),\n",
    "    batch_size = 8,\n",
    "    device = device,\n",
    "    sort = False\n",
    ")\n",
    "\n",
    "print('임베딩 벡터의 개수와 차원 : {} '.format(TEXT.vocab.vectors.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03420385",
   "metadata": {},
   "source": [
    "### TextCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "816021be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn   \n",
    "import torch.optim as optim \n",
    "import torch.nn.functional as F \n",
    "\n",
    "class TextCNN(nn.Module): \n",
    "    \n",
    "    def __init__(self, vocab_built, emb_dim, dim_channel, kernel_wins, num_class):\n",
    "        \n",
    "        super(TextCNN, self).__init__()\n",
    "        \n",
    "        self.embed = nn.Embedding(len(vocab_built), emb_dim)\n",
    "        self.embed.weight.data.copy_(vocab_built.vectors)      \n",
    "    \n",
    "        self.convs = nn.ModuleList([nn.Conv2d(1, dim_channel, (w, emb_dim)) for w in kernel_wins])\n",
    "        self.relu = nn.ReLU()                \n",
    "        self.dropout = nn.Dropout(0.4)         \n",
    "        self.fc = nn.Linear(len(kernel_wins)*dim_channel, num_class)     \n",
    "        \n",
    "    def forward(self, x):  \n",
    "      \n",
    "        emb_x = self.embed(x)           \n",
    "        emb_x = emb_x.unsqueeze(1)  \n",
    "\n",
    "        con_x = [self.relu(conv(emb_x)) for conv in self.convs]       \n",
    "\n",
    "        pool_x = [F.max_pool1d(x.squeeze(-1), x.size()[2]) for x in con_x]    \n",
    "        \n",
    "        fc_x = torch.cat(pool_x, dim=1) \n",
    "        fc_x = fc_x.squeeze(-1)       \n",
    "        fc_x = self.dropout(fc_x)         \n",
    "\n",
    "        logit = self.fc(fc_x)     \n",
    "        \n",
    "        return logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5e73e777",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_itr, optimizer):\n",
    "    \n",
    "    model.train()                               \n",
    "    corrects, train_loss = 0.0,0        \n",
    "    \n",
    "    for batch in train_itr:\n",
    "        \n",
    "        text, target = batch.text, batch.label      \n",
    "        text = torch.transpose(text, 0, 1)          \n",
    "        target.data.sub_(1)                                 \n",
    "        text, target = text.to(device), target.to(device)  \n",
    "\n",
    "        optimizer.zero_grad()                           \n",
    "        logit = model(text)                         \n",
    "    \n",
    "        loss = F.cross_entropy(logit, target)   \n",
    "        loss.backward()  \n",
    "        optimizer.step()  \n",
    "        \n",
    "        train_loss += loss.item()    \n",
    "        result = torch.max(logit,1)[1] \n",
    "        corrects += (result.view(target.size()).data == target.data).sum()\n",
    "        \n",
    "    train_loss /= len(train_itr.dataset)\n",
    "    accuracy = 100.0 * corrects / len(train_itr.dataset)\n",
    "\n",
    "    return train_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5c1df1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, device, itr):\n",
    "    \n",
    "    model.eval()\n",
    "    corrects, test_loss = 0.0, 0\n",
    "\n",
    "    for batch in itr:\n",
    "        \n",
    "        text = batch.text\n",
    "        target = batch.label\n",
    "        text = torch.transpose(text, 0, 1)\n",
    "        target.data.sub_(1)\n",
    "        text, target = text.to(device), target.to(device)\n",
    "        \n",
    "        logit = model(text)\n",
    "        loss = F.cross_entropy(logit, target)\n",
    "\n",
    "        test_loss += loss.item()\n",
    "        result = torch.max(logit,1)[1]\n",
    "        corrects += (result.view(target.size()).data == target.data).sum()\n",
    "\n",
    "    test_loss /= len(itr.dataset) \n",
    "    accuracy = 100.0 * corrects / len(itr.dataset)\n",
    "    \n",
    "    return test_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69f2882",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TextCNN(vocab, 100, 10, [3, 4, 5], 2).to(device)\n",
    "print(model)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "best_test_acc = -1\n",
    "\n",
    "for epoch in range(1, 3+1):\n",
    " \n",
    "    tr_loss, tr_acc = train(model, device, train_iter, optimizer) \n",
    "    print('Train Epoch: {} \\t Loss: {} \\t Accuracy: {}%'.format(epoch, tr_loss, tr_acc))\n",
    "    \n",
    "    val_loss, val_acc = evaluate(model, device, validation_iter)\n",
    "    print('Valid Epoch: {} \\t Loss: {} \\t Accuracy: {}%'.format(epoch, val_loss, val_acc))\n",
    "        \n",
    "    if val_acc > best_test_acc:\n",
    "        best_test_acc = val_acc\n",
    "        \n",
    "        print(\"model saves at {} accuracy\".format(best_test_acc))\n",
    "        torch.save(model.state_dict(), \"TextCNN_Best_Validation\")\n",
    "    \n",
    "    print('-----------------------------------------------------------------------------')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
